# Documentaci√≥n T√©cnica: Implementaci√≥n de thomasmol/whisper-diarization

**Modelo:** thomasmol/whisper-diarization  
**Fecha:** Diciembre 2024  
**Versi√≥n del Documento:** 1.0  
**Para:** Claude Code - Implementaci√≥n en Aplicaci√≥n M√©dica

---

## üìã Tabla de Contenidos

1. [Informaci√≥n del Modelo](#modelo)
2. [Especificaciones T√©cnicas](#specs)
3. [Inputs y Outputs](#io)
4. [Arquitectura Recomendada](#arquitectura)
5. [C√≥digo de Implementaci√≥n](#codigo)
6. [Sistema H√≠brido de Diarizaci√≥n](#hibrido)
7. [Validaci√≥n de Calidad](#calidad)
8. [Integraci√≥n con SOAP](#soap)
9. [Casos de Prueba](#pruebas)
10. [Troubleshooting](#troubleshooting)

---

## <a name="modelo"></a>1. Informaci√≥n del Modelo

### 1.1 Detalles del Modelo

```yaml
Nombre: thomasmol/whisper-diarization
Version ID: 1495a9cddc83b2203b0d8d3516e38b80fd1572ebc4bc5700ac1da56a9b3ed886
Runs: 3,389,521+ (m√°s probado en Replicate)
Base: Whisper Large V3 Turbo
Diarizaci√≥n: pyannote.audio 3.x
Idiomas: Multiidioma (espa√±ol confirmado)
```

### 1.2 Ventajas Clave

| Caracter√≠stica | Valor | Impacto |
|----------------|-------|---------|
| **Velocidad** | 18x m√°s r√°pido que audio real | Experiencia de usuario excelente |
| **Confidence** | 99% promedio | Alta confiabilidad m√©dica |
| **Simplicidad** | 4 par√°metros principales | F√°cil integraci√≥n |
| **Estabilidad** | 3.3M+ runs | Batalla-probado |
| **Costo** | ~$0.0023 por minuto | Econ√≥mico |

### 1.3 URL del Modelo

```
https://replicate.com/thomasmol/whisper-diarization
```

---

## <a name="specs"></a>2. Especificaciones T√©cnicas

### 2.1 Requisitos del Sistema

**Python:**
```bash
python >= 3.10
replicate >= 0.22.0
```

**Dependencias:**
```bash
pip install replicate pydub anthropic loguru
```

**API Token:**
```bash
# Configurar en .env
REPLICATE_API_TOKEN=r8_xxxxxxxxxxxxxxxxxxxxx
```

### 2.2 Formatos de Audio Soportados

| Formato | Extensi√≥n | Recomendado | Notas |
|---------|-----------|-------------|-------|
| MP3 | .mp3 | ‚úÖ S√≠ | M√°s com√∫n, buena compresi√≥n |
| WAV | .wav | ‚úÖ S√≠ | Sin p√©rdida, mejor calidad |
| M4A | .m4a | ‚úÖ S√≠ | Apple devices |
| FLAC | .flac | ‚ö†Ô∏è Convertir | Convertir a WAV/MP3 primero |
| OGG | .ogg | ‚ö†Ô∏è Convertir | Convertir a WAV/MP3 primero |

**L√≠mites:**
- Tama√±o m√°ximo: 25 MB (si supera, comprimir)
- Duraci√≥n m√°xima: Ilimitada (pero >1 hora puede ser lento)
- Sample rate recomendado: 16000 Hz o 44100 Hz

---

## <a name="io"></a>3. Inputs y Outputs

### 3.1 Schema de Input

```python
{
    "file": File | str,              # REQUIRED: Audio file or URL
    "file_url": str,                 # Optional: URL alternativa
    "language": str,                 # Optional: "es" para espa√±ol
    "num_speakers": int,             # Optional: N√∫mero esperado de speakers
    "translate": bool,               # Optional: False para mantener espa√±ol
    "group_segments": bool,          # Optional: True para agrupar por speaker
    "prompt": str,                   # Optional: Contexto para mejorar precisi√≥n
    "offset_seconds": int            # Optional: Iniciar desde segundo X
}
```

### 3.2 Par√°metros Detallados

#### **file** (REQUIRED)
```python
# Opci√≥n 1: Archivo local
with open("consulta.mp3", "rb") as audio:
    input = {"file": audio}

# Opci√≥n 2: URL p√∫blica
input = {"file_url": "https://ejemplo.com/audio.mp3"}
```

#### **language** (OPTIONAL pero RECOMENDADO)
```python
"language": "es"  # Espa√±ol
"language": "en"  # Ingl√©s
"language": None  # Auto-detectar (m√°s lento)
```

**C√≥digos de idioma soportados:**
```python
SUPPORTED_LANGUAGES = [
    'af', 'am', 'ar', 'as', 'az', 'ba', 'be', 'bg', 'bn', 'bo', 'br', 'bs', 
    'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 
    'fo', 'fr', 'gl', 'gu', 'ha', 'haw', 'he', 'hi', 'hr', 'ht', 'hu', 'hy',
    'id', 'is', 'it', 'ja', 'jw', 'ka', 'kk', 'km', 'kn', 'ko', 'la', 'lb',
    'ln', 'lo', 'lt', 'lv', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt',
    'my', 'ne', 'nl', 'nn', 'no', 'oc', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru',
    'sa', 'sd', 'si', 'sk', 'sl', 'sn', 'so', 'sq', 'sr', 'su', 'sv', 'sw',
    'ta', 'te', 'tg', 'th', 'tk', 'tl', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi',
    'yi', 'yo', 'zh'
]
```

#### **num_speakers** (OPTIONAL pero RECOMENDADO)
```python
"num_speakers": 2  # Para consulta m√©dica (doctor + paciente)
"num_speakers": 3  # Si hay enfermera/acompa√±ante
"num_speakers": None  # Auto-detectar (menos preciso)
```

‚ö†Ô∏è **IMPORTANTE:** El modelo puede ignorar este par√°metro si detecta un n√∫mero diferente de speakers. Si solo detecta 1 speaker cuando esperabas 2, usa el sistema h√≠brido (ver secci√≥n 6).

#### **translate** (OPTIONAL)
```python
"translate": False  # Mantener en espa√±ol original (RECOMENDADO)
"translate": True   # Traducir a ingl√©s (NO usar para app m√©dica)
```

#### **group_segments** (OPTIONAL)
```python
"group_segments": True   # Agrupa frases del mismo speaker (RECOMENDADO)
"group_segments": False  # Cada palabra es un segmento (muy granular)
```

**Ejemplo de diferencia:**

```python
# group_segments: False
[
  {"text": " He", "speaker": "SPEAKER_00"},
  {"text": " estado", "speaker": "SPEAKER_00"},
  {"text": " teniendo", "speaker": "SPEAKER_00"}
]

# group_segments: True
[
  {"text": "He estado teniendo problemas al levantarme.", "speaker": "SPEAKER_00"}
]
```

#### **prompt** (OPTIONAL pero √öTIL)
```python
"prompt": "Doctor, paciente, consulta m√©dica, s√≠ntomas, diagn√≥stico, tratamiento"
```

Este par√°metro ayuda al modelo a:
- Mejorar precisi√≥n en terminolog√≠a m√©dica
- Entender el contexto del audio
- Reducir errores en palabras t√©cnicas

**Prompts recomendados por especialidad:**

```python
MEDICAL_PROMPTS = {
    'general': 'Doctor, paciente, consulta m√©dica, s√≠ntomas, diagn√≥stico, tratamiento',
    'cardiologia': 'Doctor, paciente, presi√≥n arterial, coraz√≥n, arritmia, electrocardiograma',
    'pediatria': 'Doctor, paciente, ni√±o, fiebre, vacunas, desarrollo',
    'ginecologia': 'Doctor, paciente, menstruaci√≥n, embarazo, anticonceptivos'
}
```

### 3.3 Schema de Output

```python
{
    "language": str,                # Idioma detectado (ej: "es")
    "segments": [                   # Array de segmentos transcritos
        {
            "start": float,         # Tiempo inicio (segundos)
            "end": float,           # Tiempo fin (segundos)
            "text": str,            # Texto transcrito
            "speaker": str,         # "SPEAKER_00", "SPEAKER_01", etc.
            "duration": float,      # Duraci√≥n del segmento
            "avg_logprob": float,   # Probabilidad logar√≠tmica promedio
            "words": [              # Array de palabras individuales
                {
                    "word": str,          # Palabra
                    "start": float,       # Tiempo inicio palabra
                    "end": float,         # Tiempo fin palabra
                    "speaker": str,       # Speaker de esta palabra
                    "probability": float  # Confianza (0-1)
                }
            ]
        }
    ],
    "num_speakers": int            # N√∫mero de speakers detectados
}
```

### 3.4 Ejemplo de Output Completo

```json
{
  "language": "es",
  "num_speakers": 1,
  "segments": [
    {
      "start": 3.18,
      "end": 5.6,
      "text": "He estado teniendo problemas al levantarme.",
      "speaker": "SPEAKER_00",
      "duration": 2.42,
      "avg_logprob": -0.114,
      "words": [
        {
          "word": " He",
          "start": 3.18,
          "end": 3.74,
          "speaker": "SPEAKER_00",
          "probability": 0.892
        },
        {
          "word": " estado",
          "start": 3.74,
          "end": 4.02,
          "speaker": "SPEAKER_00",
          "probability": 0.9995
        },
        {
          "word": " teniendo",
          "start": 4.02,
          "end": 4.46,
          "speaker": "SPEAKER_00",
          "probability": 0.9995
        }
      ]
    }
  ]
}
```

---

## <a name="arquitectura"></a>4. Arquitectura Recomendada

### 4.1 Flujo General

```mermaid
graph TB
    A[Audio de Consulta] --> B[Validar Audio]
    B --> C{¬øFormato v√°lido?}
    C -->|No| D[Convertir a MP3]
    C -->|S√≠| E{¬øTama√±o > 25MB?}
    D --> E
    E -->|S√≠| F[Comprimir Audio]
    E -->|No| G[Transcribir con thomasmol]
    F --> G
    G --> H{¬øSpeakers detectados?}
    H -->|2+| I[Mapear a Doctor/Patient]
    H -->|1| J[Sistema H√≠brido]
    I --> K[Validar Confianza]
    J --> K
    K --> L{¬øPalabras <85%?}
    L -->|S√≠| M[Marcar para Revisi√≥n]
    L -->|No| N[Generar SOAP]
    M --> N
    N --> O[Guardar Resultado]
```

### 4.2 Estructura de Directorios

```
medical-transcription-app/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ transcription/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ thomasmol_client.py      # Cliente del modelo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio_validator.py       # Validaci√≥n de audio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio_processor.py       # Conversi√≥n/compresi√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ speaker_assigner.py      # Sistema h√≠brido
‚îÇ   ‚îú‚îÄ‚îÄ quality/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confidence_checker.py    # Validaci√≥n de confianza
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ medical_terms.py         # Diccionario m√©dico
‚îÇ   ‚îú‚îÄ‚îÄ soap/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generator.py             # Generaci√≥n SOAP con Claude
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ main.py                  # FastAPI endpoints
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ settings.py                  # Configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ medical_prompts.json         # Prompts por especialidad
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_transcription.py
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îÇ       ‚îî‚îÄ‚îÄ sample_audios/
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## <a name="codigo"></a>5. C√≥digo de Implementaci√≥n

### 5.1 Cliente de Transcripci√≥n

**src/transcription/thomasmol_client.py:**

```python
"""
Cliente para el modelo thomasmol/whisper-diarization
"""
import replicate
from typing import Dict, Any, Optional
from pathlib import Path
import json
from loguru import logger

class ThomasmolClient:
    """
    Cliente optimizado para thomasmol/whisper-diarization
    """
    
    MODEL_VERSION = "1495a9cddc83b2203b0d8d3516e38b80fd1572ebc4bc5700ac1da56a9b3ed886"
    
    def __init__(self, api_token: Optional[str] = None):
        """
        Inicializa el cliente
        
        Args:
            api_token: Token de Replicate (si no se provee, usa env var)
        """
        self.client = replicate.Client(api_token=api_token)
        logger.info("ThomasmolClient inicializado")
    
    def transcribe(
        self,
        audio_path: str,
        language: str = "es",
        num_speakers: int = 2,
        prompt: Optional[str] = None,
        group_segments: bool = True
    ) -> Dict[str, Any]:
        """
        Transcribe audio con diarizaci√≥n
        
        Args:
            audio_path: Ruta al archivo de audio
            language: C√≥digo de idioma (ej: "es")
            num_speakers: N√∫mero esperado de speakers
            prompt: Contexto para mejorar precisi√≥n
            group_segments: Agrupar segmentos por speaker
        
        Returns:
            Dict con transcripci√≥n y metadata
        
        Raises:
            FileNotFoundError: Si audio no existe
            ValueError: Si par√°metros son inv√°lidos
        """
        # Validar archivo
        audio_file = Path(audio_path)
        if not audio_file.exists():
            raise FileNotFoundError(f"Audio no encontrado: {audio_path}")
        
        logger.info(f"Transcribiendo: {audio_path}")
        logger.info(f"Par√°metros: lang={language}, speakers={num_speakers}")
        
        # Preparar prompt
        if prompt is None:
            prompt = self._get_default_prompt()
        
        try:
            # Ejecutar modelo
            with open(audio_path, "rb") as audio:
                output = self.client.run(
                    f"thomasmol/whisper-diarization:{self.MODEL_VERSION}",
                    input={
                        "file": audio,
                        "language": language,
                        "num_speakers": num_speakers,
                        "prompt": prompt,
                        "group_segments": group_segments,
                        "translate": False  # Mantener idioma original
                    }
                )
            
            # Validar output
            if not output or 'segments' not in output:
                raise ValueError("Output inv√°lido del modelo")
            
            # Agregar metadata
            result = {
                'transcription': output,
                'metadata': {
                    'audio_file': audio_path,
                    'language': output.get('language', language),
                    'num_speakers_detected': output.get('num_speakers', 0),
                    'num_speakers_expected': num_speakers,
                    'total_segments': len(output.get('segments', [])),
                    'model_version': self.MODEL_VERSION
                }
            }
            
            logger.success(
                f"Transcripci√≥n exitosa: {result['metadata']['total_segments']} segmentos, "
                f"{result['metadata']['num_speakers_detected']} speakers detectados"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Error en transcripci√≥n: {e}")
            raise
    
    def _get_default_prompt(self) -> str:
        """
        Prompt por defecto para consultas m√©dicas
        """
        return (
            "Doctor, paciente, consulta m√©dica, s√≠ntomas, diagn√≥stico, "
            "tratamiento, medicamento, alergia, presi√≥n arterial, an√°lisis"
        )
    
    def transcribe_batch(
        self,
        audio_paths: list[str],
        **kwargs
    ) -> list[Dict[str, Any]]:
        """
        Transcribe m√∫ltiples audios
        
        Args:
            audio_paths: Lista de rutas a archivos
            **kwargs: Argumentos para transcribe()
        
        Returns:
            Lista de resultados
        """
        results = []
        
        for i, path in enumerate(audio_paths, 1):
            logger.info(f"Procesando audio {i}/{len(audio_paths)}")
            try:
                result = self.transcribe(path, **kwargs)
                results.append(result)
            except Exception as e:
                logger.error(f"Error procesando {path}: {e}")
                results.append({'error': str(e), 'audio_path': path})
        
        return results

# Singleton
thomasmol_client = ThomasmolClient()
```

### 5.2 Validador de Audio

**src/transcription/audio_validator.py:**

```python
"""
Validaci√≥n y procesamiento de archivos de audio
"""
from pathlib import Path
from pydub import AudioSegment
from loguru import logger
import os

class AudioValidator:
    """
    Valida y procesa archivos de audio antes de transcripci√≥n
    """
    
    SUPPORTED_FORMATS = ['.mp3', '.wav', '.m4a', '.flac', '.ogg']
    MAX_SIZE_MB = 25
    MAX_SIZE_BYTES = MAX_SIZE_MB * 1024 * 1024
    
    @staticmethod
    def validate(audio_path: str) -> tuple[bool, str]:
        """
        Valida archivo de audio
        
        Returns:
            (is_valid, message)
        """
        path = Path(audio_path)
        
        # Existe?
        if not path.exists():
            return False, f"Archivo no existe: {audio_path}"
        
        # Formato soportado?
        if path.suffix.lower() not in AudioValidator.SUPPORTED_FORMATS:
            return False, f"Formato no soportado: {path.suffix}"
        
        # Tama√±o OK?
        size_mb = path.stat().st_size / (1024 * 1024)
        if size_mb > AudioValidator.MAX_SIZE_MB:
            return False, f"Archivo muy grande: {size_mb:.2f}MB (m√°x: {AudioValidator.MAX_SIZE_MB}MB)"
        
        # Intentar cargar
        try:
            AudioSegment.from_file(audio_path)
        except Exception as e:
            return False, f"Audio corrupto o inv√°lido: {e}"
        
        return True, "Audio v√°lido"
    
    @staticmethod
    def convert_to_mp3(
        audio_path: str,
        output_path: Optional[str] = None
    ) -> str:
        """
        Convierte audio a MP3
        
        Args:
            audio_path: Audio original
            output_path: Ruta de salida (si None, usa temp)
        
        Returns:
            Ruta al MP3 generado
        """
        logger.info(f"Convirtiendo a MP3: {audio_path}")
        
        # Cargar audio
        audio = AudioSegment.from_file(audio_path)
        
        # Ruta de salida
        if output_path is None:
            output_path = str(Path(audio_path).with_suffix('.mp3'))
        
        # Convertir a mono (mejor para diarizaci√≥n)
        audio = audio.set_channels(1)
        
        # Exportar
        audio.export(output_path, format='mp3', bitrate='128k')
        
        logger.success(f"MP3 generado: {output_path}")
        return output_path
    
    @staticmethod
    def compress_audio(
        audio_path: str,
        target_mb: int = 20,
        output_path: Optional[str] = None
    ) -> str:
        """
        Comprime audio si excede tama√±o objetivo
        
        Args:
            audio_path: Audio a comprimir
            target_mb: Tama√±o objetivo en MB
            output_path: Ruta de salida
        
        Returns:
            Ruta al audio comprimido
        """
        logger.info(f"Comprimiendo audio a ~{target_mb}MB")
        
        # Cargar
        audio = AudioSegment.from_file(audio_path)
        
        # Calcular bitrate necesario
        duration_seconds = len(audio) / 1000
        target_bytes = target_mb * 1024 * 1024
        target_bitrate = int((target_bytes * 8) / duration_seconds)
        
        # Limitar bitrate m√≠nimo
        target_bitrate = max(64, min(target_bitrate, 320))
        
        # Ruta de salida
        if output_path is None:
            output_path = str(Path(audio_path).with_name(
                f"{Path(audio_path).stem}_compressed{Path(audio_path).suffix}"
            ))
        
        # Exportar comprimido
        audio.export(
            output_path,
            format='mp3',
            bitrate=f'{target_bitrate}k'
        )
        
        new_size = Path(output_path).stat().st_size / (1024 * 1024)
        logger.success(f"Audio comprimido: {new_size:.2f}MB (bitrate: {target_bitrate}kbps)")
        
        return output_path
    
    @staticmethod
    def prepare_audio(audio_path: str) -> str:
        """
        Pipeline completo de preparaci√≥n
        
        Returns:
            Ruta al audio preparado
        """
        path = Path(audio_path)
        
        # 1. Validar
        is_valid, message = AudioValidator.validate(audio_path)
        if not is_valid:
            raise ValueError(message)
        
        # 2. Convertir a MP3 si no lo es
        if path.suffix.lower() != '.mp3':
            audio_path = AudioValidator.convert_to_mp3(audio_path)
            path = Path(audio_path)
        
        # 3. Comprimir si es muy grande
        size_mb = path.stat().st_size / (1024 * 1024)
        if size_mb > AudioValidator.MAX_SIZE_MB:
            audio_path = AudioValidator.compress_audio(audio_path)
        
        return audio_path

# Singleton
audio_validator = AudioValidator()
```

### 5.3 Sistema H√≠brido de Asignaci√≥n de Speakers

**src/transcription/speaker_assigner.py:**

```python
"""
Sistema h√≠brido para asignar speakers cuando diarizaci√≥n autom√°tica falla
"""
from typing import Dict, List, Any
from loguru import logger
import json

class SpeakerAssigner:
    """
    Asigna speakers usando an√°lisis de contenido + heur√≠sticas
    """
    
    # Patrones de lenguaje m√©dico
    DOCTOR_PATTERNS = [
        # Preguntas diagn√≥sticas
        '¬øcu√°ndo', '¬øqu√©', '¬øc√≥mo', '¬ød√≥nde', '¬øpor qu√©',
        
        # Afirmaciones cl√≠nicas
        'tiene', 'presenta', 'muestra', 'indica',
        
        # Acciones m√©dicas
        'voy a', 'vamos a', 'tengo algo', 'le recomiendoque', 'prescribir', 'recomendar',
        
        # Lenguaje t√©cnico
        'los estudios', 'el an√°lisis', 'la radiograf√≠a', 'el examen',
        'contraataca', 'dirigida', 'tratamiento', 'diagn√≥stico',
        
        # Explicaciones
        'esto significa', 'lo que pasa es', 'es normal', 'no se preocupe'
    ]
    
    PATIENT_PATTERNS = [
        # S√≠ntomas subjetivos
        'me duele', 'siento', 'tengo', 'he estado', 'he tenido',
        
        # Temporalidad
        'hace', 'desde hace', 'd√≠as', 'semanas', 'meses',
        
        # Descripciones personales
        'problemas al', 'no puedo', 'me cuesta', 'cuando',
        
        # Respuestas simples
        's√≠ doctor', 'no doctor', 'creo que', 'no estoy seguro'
    ]
    
    def assign_speakers(
        self,
        segments: List[Dict[str, Any]],
        num_speakers_detected: int
    ) -> List[Dict[str, Any]]:
        """
        Pipeline principal de asignaci√≥n
        
        Args:
            segments: Segmentos de transcripci√≥n
            num_speakers_detected: N√∫mero detectado por el modelo
        
        Returns:
            Segmentos con speakers asignados
        """
        if num_speakers_detected >= 2:
            logger.info(f"{num_speakers_detected} speakers detectados, mapeando a roles")
            return self._map_to_roles(segments)
        else:
            logger.warning("Solo 1 speaker detectado, usando heur√≠stica")
            return self._assign_by_heuristics(segments)
    
    def _assign_by_heuristics(
        self,
        segments: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Asigna speakers usando an√°lisis de contenido
        """
        for i, segment in enumerate(segments):
            text = segment['text'].lower()
            
            # Calcular scores
            doctor_score = sum(
                1 for pattern in self.DOCTOR_PATTERNS
                if pattern in text
            )
            
            patient_score = sum(
                1 for pattern in self.PATIENT_PATTERNS
                if pattern in text
            )
            
            # Asignar speaker
            if doctor_score > patient_score:
                speaker = 'Doctor'
                confidence = 'heuristic_high'
            elif patient_score > doctor_score:
                speaker = 'Patient'
                confidence = 'heuristic_high'
            elif i == 0:
                # Primera frase t√≠picamente es el paciente (motivo de consulta)
                speaker = 'Patient'
                confidence = 'heuristic_medium'
            else:
                # Alternar con el anterior
                prev_speaker = segments[i-1].get('speaker', 'Doctor')
                speaker = 'Patient' if prev_speaker == 'Doctor' else 'Doctor'
                confidence = 'heuristic_low'
            
            # Actualizar segmento
            segment['speaker'] = speaker
            segment['speaker_confidence'] = confidence
            
            # Actualizar palabras
            for word in segment.get('words', []):
                word['speaker'] = speaker
        
        # Log estad√≠sticas
        doctor_count = sum(1 for s in segments if s['speaker'] == 'Doctor')
        patient_count = len(segments) - doctor_count
        
        logger.info(
            f"Asignaci√≥n heur√≠stica: {doctor_count} Doctor, {patient_count} Patient"
        )
        
        return segments
    
    def _map_to_roles(
        self,
        segments: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Mapea SPEAKER_00/01 a Doctor/Patient basado en contenido
        """
        # Analizar cada speaker
        speaker_stats = {}
        
        for segment in segments:
            speaker = segment['speaker']
            if speaker not in speaker_stats:
                speaker_stats[speaker] = {'doctor': 0, 'patient': 0}
            
            text = segment['text'].lower()
            
            # Contar patrones
            for pattern in self.DOCTOR_PATTERNS:
                if pattern in text:
                    speaker_stats[speaker]['doctor'] += 1
            
            for pattern in self.PATIENT_PATTERNS:
                if pattern in text:
                    speaker_stats[speaker]['patient'] += 1
        
        # Determinar mapeo
        mapping = {}
        for speaker, stats in speaker_stats.items():
            if stats['doctor'] > stats['patient']:
                mapping[speaker] = 'Doctor'
            else:
                mapping[speaker] = 'Patient'
        
        # Aplicar mapeo
        for segment in segments:
            original_speaker = segment['speaker']
            segment['speaker'] = mapping.get(original_speaker, original_speaker)
            segment['speaker_confidence'] = 'automatic'
            
            # Actualizar palabras
            for word in segment.get('words', []):
                word['speaker'] = segment['speaker']
        
        logger.info(f"Mapeo aplicado: {mapping}")
        return segments
    
    def validate_assignment(
        self,
        segments: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Valida la calidad de la asignaci√≥n
        
        Returns:
            Estad√≠sticas de validaci√≥n
        """
        total = len(segments)
        doctor = sum(1 for s in segments if s['speaker'] == 'Doctor')
        patient = total - doctor
        
        heuristic = sum(
            1 for s in segments
            if s.get('speaker_confidence', '').startswith('heuristic')
        )
        
        return {
            'total_segments': total,
            'doctor_segments': doctor,
            'patient_segments': patient,
            'doctor_percentage': (doctor / total * 100) if total > 0 else 0,
            'heuristic_assignments': heuristic,
            'heuristic_percentage': (heuristic / total * 100) if total > 0 else 0,
            'quality': 'high' if heuristic == 0 else 'medium' if heuristic < total/2 else 'low'
        }

# Singleton
speaker_assigner = SpeakerAssigner()
```

### 5.4 Validador de Confianza

**src/quality/confidence_checker.py:**

```python
"""
Validaci√≥n de confianza de transcripci√≥n
"""
from typing import Dict, List, Any
from loguru import logger
import json
from pathlib import Path

class ConfidenceChecker:
    """
    Valida confianza de transcripci√≥n y detecta t√©rminos cr√≠ticos
    """
    
    # Thresholds
    CONFIDENCE_CRITICAL = 0.85  # Para t√©rminos m√©dicos cr√≠ticos
    CONFIDENCE_GENERAL = 0.70   # Para texto general
    
    def __init__(self, medical_terms_path: str = "config/medical_terms.json"):
        """
        Inicializa con diccionario de t√©rminos m√©dicos
        """
        self.medical_terms = self._load_medical_terms(medical_terms_path)
        self.critical_terms = self._flatten_critical_terms()
    
    def _load_medical_terms(self, path: str) -> Dict:
        """
        Carga diccionario de t√©rminos m√©dicos
        """
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"Diccionario m√©dico no encontrado: {path}")
            return self._get_default_terms()
    
    def _get_default_terms(self) -> Dict:
        """
        T√©rminos m√©dicos por defecto
        """
        return {
            "critical_terms": {
                "allergies": [
                    "penicilina", "penicillin", "aspirina", "aspirin",
                    "ibuprofeno", "ibuprofen", "amoxicilina", "amoxicillin",
                    "sulfa", "mariscos", "latex"
                ],
                "medications": [
                    "metformina", "metformin", "insulina", "insulin",
                    "losart√°n", "losartan", "enalapril", "warfarina",
                    "anticoagulante", "digit√°licos"
                ],
                "conditions": [
                    "infarto", "hemorragia", "embolia", "stroke",
                    "anafilaxia", "anaphylaxis", "convulsi√≥n", "seizure",
                    "shock", "coma"
                ]
            },
            "vital_signs": {
                "patterns": [
                    r"\d+/\d+",           # 120/80
                    r"\d+\s*mg/dL",       # 100 mg/dL
                    r"\d+\s*¬∞[CF]"        # 37.5 ¬∞C
                ]
            }
        }
    
    def _flatten_critical_terms(self) -> List[str]:
        """
        Aplana t√©rminos cr√≠ticos en lista √∫nica
        """
        terms = []
        for category in self.medical_terms.get('critical_terms', {}).values():
            terms.extend([t.lower() for t in category])
        return terms
    
    def check(
        self,
        transcription: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Valida confianza de transcripci√≥n
        
        Returns:
            Reporte de calidad
        """
        logger.info("Validando confianza de transcripci√≥n...")
        
        report = {
            'overall_confidence': 0.0,
            'low_confidence_words': [],
            'critical_alerts': [],
            'statistics': {
                'total_words': 0,
                'total_segments': 0,
                'words_below_70': 0,
                'words_below_85': 0
            }
        }
        
        all_confidences = []
        
        for segment in transcription.get('segments', []):
            report['statistics']['total_segments'] += 1
            
            for word_data in segment.get('words', []):
                word = word_data.get('word', '').strip()
                confidence = word_data.get('probability', 1.0)
                start_time = word_data.get('start', 0)
                speaker = word_data.get('speaker', 'UNKNOWN')
                
                report['statistics']['total_words'] += 1
                all_confidences.append(confidence)
                
                # Detectar baja confianza general
                if confidence < self.CONFIDENCE_GENERAL:
                    report['statistics']['words_below_70'] += 1
                    report['low_confidence_words'].append({
                        'word': word,
                        'confidence': confidence,
                        'time': start_time,
                        'speaker': speaker
                    })
                
                if confidence < self.CONFIDENCE_CRITICAL:
                    report['statistics']['words_below_85'] += 1
                
                # CR√çTICO: T√©rminos m√©dicos con baja confianza
                if self._is_critical_term(word):
                    if confidence < self.CONFIDENCE_CRITICAL:
                        report['critical_alerts'].append({
                            'word': word,
                            'confidence': confidence,
                            'time': start_time,
                            'speaker': speaker,
                            'severity': 'HIGH',
                            'message': f'T√©rmino m√©dico cr√≠tico con baja confianza: {word}'
                        })
        
        # Calcular confianza general
        if all_confidences:
            report['overall_confidence'] = sum(all_confidences) / len(all_confidences)
        
        # Clasificar calidad
        report['quality_level'] = self._classify_quality(report)
        
        logger.info(
            f"Validaci√≥n completada: "
            f"Confianza={report['overall_confidence']:.2%}, "
            f"Alertas={len(report['critical_alerts'])}, "
            f"Calidad={report['quality_level']}"
        )
        
        return report
    
    def _is_critical_term(self, word: str) -> bool:
        """
        Verifica si palabra es t√©rmino m√©dico cr√≠tico
        """
        word_clean = word.lower().strip('.,;:!?')
        return word_clean in self.critical_terms
    
    def _classify_quality(self, report: Dict) -> str:
        """
        Clasifica calidad general
        """
        conf = report['overall_confidence']
        alerts = len(report['critical_alerts'])
        
        if conf >= 0.95 and alerts == 0:
            return 'excellent'
        elif conf >= 0.85 and alerts <= 2:
            return 'good'
        elif conf >= 0.70 and alerts <= 5:
            return 'acceptable'
        else:
            return 'poor'

# Singleton
confidence_checker = ConfidenceChecker()
```

---

## <a name="hibrido"></a>6. Sistema H√≠brido de Diarizaci√≥n

### 6.1 L√≥gica de Decisi√≥n

```python
def process_transcription(audio_path: str) -> Dict:
    """
    Pipeline completo con sistema h√≠brido
    """
    # 1. Transcribir
    result = thomasmol_client.transcribe(audio_path)
    transcription = result['transcription']
    
    # 2. Verificar speakers
    speakers_detected = transcription['num_speakers']
    
    if speakers_detected >= 2:
        # Diarizaci√≥n autom√°tica funcion√≥
        segments = speaker_assigner.assign_speakers(
            transcription['segments'],
            speakers_detected
        )
        method = 'automatic'
    else:
        # Usar heur√≠stica
        segments = speaker_assigner.assign_speakers(
            transcription['segments'],
            speakers_detected
        )
        method = 'heuristic'
    
    # 3. Validar calidad
    quality_report = confidence_checker.check(transcription)
    assignment_stats = speaker_assigner.validate_assignment(segments)
    
    return {
        'segments': segments,
        'quality_report': quality_report,
        'assignment_stats': assignment_stats,
        'diarization_method': method,
        'needs_review': (
            quality_report['quality_level'] in ['poor', 'acceptable'] or
            len(quality_report['critical_alerts']) > 0 or
            assignment_stats['quality'] == 'low'
        )
    }
```

### 6.2 Configuraci√≥n de Prompts por Especialidad

**config/medical_prompts.json:**

```json
{
  "general": {
    "prompt": "Doctor, paciente, consulta m√©dica, s√≠ntomas, diagn√≥stico, tratamiento, medicamento, alergia",
    "critical_terms": ["alergia", "medicamento", "presi√≥n", "az√∫car", "dolor"]
  },
  "cardiologia": {
    "prompt": "Doctor, paciente, coraz√≥n, presi√≥n arterial, arritmia, electrocardiograma, angina, infarto",
    "critical_terms": ["presi√≥n", "infarto", "arritmia", "angina", "anticoagulante"]
  },
  "pediatria": {
    "prompt": "Doctor, paciente, ni√±o, fiebre, vacunas, desarrollo, peso, talla, crecimiento",
    "critical_terms": ["vacuna", "fiebre", "convulsi√≥n", "deshidrataci√≥n", "alergia"]
  },
  "endocrinologia": {
    "prompt": "Doctor, paciente, diabetes, glucosa, insulina, tiroides, hormona, az√∫car",
    "critical_terms": ["insulina", "glucosa", "hipoglucemia", "cetoacidosis"]
  }
}
```

---

## <a name="calidad"></a>7. Validaci√≥n de Calidad

### 7.1 Criterios de Validaci√≥n

```python
VALIDATION_CRITERIA = {
    'excellent': {
        'overall_confidence': >= 0.95,
        'critical_alerts': 0,
        'low_confidence_words': <= 2,
        'diarization_quality': 'high'
    },
    'good': {
        'overall_confidence': >= 0.85,
        'critical_alerts': <= 2,
        'low_confidence_words': <= 5,
        'diarization_quality': ['high', 'medium']
    },
    'acceptable': {
        'overall_confidence': >= 0.70,
        'critical_alerts': <= 5,
        'low_confidence_words': <= 10,
        'diarization_quality': ['high', 'medium', 'low']
    },
    'poor': {
        'overall_confidence': < 0.70,
        'critical_alerts': > 5,
        'requires_manual_review': True
    }
}
```

### 7.2 Acci√≥n por Nivel de Calidad

| Calidad | Acci√≥n | Proceso |
|---------|--------|---------|
| `excellent` | ‚úÖ Procesar directamente | SOAP autom√°tico |
| `good` | ‚ö†Ô∏è Revisar alertas | SOAP con marcadores de revisi√≥n |
| `acceptable` | ‚ö†Ô∏è‚ö†Ô∏è Revisi√≥n obligatoria | SOAP + validaci√≥n manual |
| `poor` | ‚ùå Bloquear SOAP | Retranscribir o correcci√≥n manual |

---

## <a name="soap"></a>8. Integraci√≥n con SOAP

### 8.1 Generador SOAP con Claude

**src/soap/generator.py:**

```python
"""
Generaci√≥n de notas SOAP usando Claude
"""
from anthropic import Anthropic
from typing import Dict, Any
from loguru import logger
import os

class SOAPGenerator:
    """
    Genera notas SOAP desde transcripci√≥n
    """
    
    def __init__(self):
        self.client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
    
    def generate(
        self,
        segments: list[Dict],
        quality_report: Dict
    ) -> Dict[str, Any]:
        """
        Genera nota SOAP
        """
        # Formatear transcripci√≥n
        transcript = self._format_transcript(segments)
        
        # Formatear alertas
        alerts = self._format_alerts(quality_report)
        
        # Prompt
        prompt = self._build_prompt(transcript, alerts)
        
        # Llamar Claude
        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4000,
            temperature=0.3,
            messages=[{"role": "user", "content": prompt}]
        )
        
        soap_note = response.content[0].text
        
        return {
            'soap_note': soap_note,
            'quality_alerts': quality_report.get('critical_alerts', []),
            'needs_review': len(quality_report.get('critical_alerts', [])) > 0
        }
    
    def _format_transcript(self, segments: list) -> str:
        """Formatea transcripci√≥n para prompt"""
        lines = []
        for seg in segments:
            speaker = seg.get('speaker', 'UNKNOWN')
            text = seg.get('text', '')
            time = seg.get('start', 0)
            conf = seg.get('speaker_confidence', 'automatic')
            
            marker = ' [?]' if 'heuristic' in conf else ''
            lines.append(f"[{time:.1f}s] {speaker}{marker}: {text}")
        
        return "\n".join(lines)
    
    def _format_alerts(self, quality_report: Dict) -> str:
        """Formatea alertas de calidad"""
        if not quality_report.get('critical_alerts'):
            return "‚úÖ Sin alertas cr√≠ticas"
        
        alerts = ["‚ö†Ô∏è ALERTAS DE CALIDAD - Verificar manualmente:"]
        for alert in quality_report['critical_alerts']:
            alerts.append(
                f"- '{alert['word']}' (confianza: {alert['confidence']:.0%}) "
                f"@ {alert['time']:.1f}s"
            )
        
        return "\n".join(alerts)
    
    def _build_prompt(self, transcript: str, alerts: str) -> str:
        """Construye prompt para Claude"""
        return f"""Eres un asistente m√©dico experto. Convierte esta transcripci√≥n de consulta a formato SOAP.

TRANSCRIPCI√ìN:
{transcript}

{alerts}

INSTRUCCIONES:
1. Genera nota SOAP con secciones: S, O, A, P
2. Marca t√©rminos con baja confianza: [VERIFICAR: palabra]
3. Extrae: alergias, medicamentos, valores vitales
4. Si speakers marcados con [?], indica que la asignaci√≥n es aproximada

NOTA SOAP:"""

# Singleton
soap_generator = SOAPGenerator()
```

---

## <a name="pruebas"></a>9. Casos de Prueba

### 9.1 Audio de Prueba Sint√©tico

```python
# tests/create_test_audio.py
from gtts import gTTS
from pydub import AudioSegment
import os

def create_test_consultation():
    """Crea audio de prueba"""
    dialogue = [
        ("Patient", "Buenos d√≠as doctor, he estado teniendo dolor de cabeza muy fuerte desde hace tres d√≠as."),
        ("Doctor", "¬øCu√°ndo empez√≥ exactamente el dolor? ¬øHa tenido fiebre?"),
        ("Patient", "Empez√≥ el lunes por la ma√±ana. No he tenido fiebre, solo el dolor."),
        ("Doctor", "¬øToma alg√∫n medicamento actualmente? ¬øTiene alergias?"),
        ("Patient", "Tomo losart√°n para la presi√≥n. Soy al√©rgico a la penicilina."),
        ("Doctor", "Entiendo. Voy a recetarle ibuprofeno para el dolor. Tome uno cada ocho horas."),
    ]
    
    audio_segments = []
    for i, (speaker, text) in enumerate(dialogue):
        tts = gTTS(text=text, lang='es', slow=False)
        temp_file = f"temp_{i}.mp3"
        tts.save(temp_file)
        
        audio = AudioSegment.from_mp3(temp_file)
        silence = AudioSegment.silent(duration=800)
        audio_segments.append(audio + silence)
        
        os.remove(temp_file)
    
    final_audio = sum(audio_segments)
    output_path = "tests/fixtures/sample_audios/test_consultation.mp3"
    final_audio.export(output_path, format="mp3")
    
    print(f"‚úÖ Audio creado: {output_path}")

if __name__ == "__main__":
    create_test_consultation()
```

### 9.2 Script de Prueba

```python
# tests/test_full_pipeline.py
import sys
sys.path.append('.')

from src.transcription.thomasmol_client import thomasmol_client
from src.transcription.speaker_assigner import speaker_assigner
from src.quality.confidence_checker import confidence_checker
from src.soap.generator import soap_generator
from loguru import logger
import json

def test_full_pipeline(audio_path: str):
    """
    Prueba el pipeline completo
    """
    logger.info("="*60)
    logger.info("TEST: Pipeline Completo")
    logger.info("="*60)
    
    # 1. Transcribir
    logger.info("\nüìù PASO 1: Transcripci√≥n")
    result = thomasmol_client.transcribe(audio_path)
    logger.info(f"‚úÖ {result['metadata']['total_segments']} segmentos")
    
    # 2. Asignar speakers
    logger.info("\nüë• PASO 2: Asignaci√≥n de Speakers")
    segments = speaker_assigner.assign_speakers(
        result['transcription']['segments'],
        result['metadata']['num_speakers_detected']
    )
    assignment_stats = speaker_assigner.validate_assignment(segments)
    logger.info(f"‚úÖ {assignment_stats['doctor_segments']} Doctor, {assignment_stats['patient_segments']} Patient")
    
    # 3. Validar calidad
    logger.info("\nüîç PASO 3: Validaci√≥n de Calidad")
    result['transcription']['segments'] = segments
    quality_report = confidence_checker.check(result['transcription'])
    logger.info(f"‚úÖ Confianza: {quality_report['overall_confidence']:.2%}")
    logger.info(f"‚ö†Ô∏è  Alertas: {len(quality_report['critical_alerts'])}")
    
    # 4. Generar SOAP
    logger.info("\nüìÑ PASO 4: Generaci√≥n SOAP")
    soap_result = soap_generator.generate(segments, quality_report)
    logger.info("‚úÖ SOAP generada")
    
    # Guardar resultados
    with open('test_results.json', 'w', encoding='utf-8') as f:
        json.dump({
            'transcription': segments,
            'quality': quality_report,
            'assignment': assignment_stats,
            'soap': soap_result
        }, f, indent=2, ensure_ascii=False)
    
    logger.info("\nüíæ Resultados guardados en test_results.json")
    
    # Mostrar SOAP
    logger.info("\n"+"="*60)
    logger.info("NOTA SOAP:")
    logger.info("="*60)
    print(soap_result['soap_note'])
    
    return {
        'segments': segments,
        'quality_report': quality_report,
        'soap': soap_result
    }

if __name__ == "__main__":
    test_full_pipeline("tests/fixtures/sample_audios/test_consultation.mp3")
```

---

## <a name="troubleshooting"></a>10. Troubleshooting

### 10.1 Problemas Comunes

#### **Error: "Audio file too large"**

```python
# Soluci√≥n: Comprimir antes de enviar
from src.transcription.audio_validator import audio_validator

compressed = audio_validator.compress_audio("audio.mp3", target_mb=20)
result = thomasmol_client.transcribe(compressed)
```

#### **Error: "Only 1 speaker detected"**

```python
# Esto es esperado en algunos audios
# El sistema h√≠brido se encarga autom√°ticamente

result = process_transcription(audio_path)
if result['diarization_method'] == 'heuristic':
    logger.warning("Usando asignaci√≥n heur√≠stica")
```

#### **Error: "Low confidence on critical terms"**

```python
# Marcar para revisi√≥n manual
if len(quality_report['critical_alerts']) > 0:
    # Mostrar alertas al usuario
    for alert in quality_report['critical_alerts']:
        print(f"‚ö†Ô∏è Revisar: {alert['word']} @ {alert['time']:.1f}s")
```

### 10.2 Optimizaciones de Performance

```python
# Para procesar m√∫ltiples audios en paralelo
from concurrent.futures import ThreadPoolExecutor

def batch_transcribe(audio_paths: list):
    with ThreadPoolExecutor(max_workers=3) as executor:
        results = list(executor.map(process_transcription, audio_paths))
    return results
```

---

## üìù Resumen para Claude Code

### Implementaci√≥n Paso a Paso

1. **Setup inicial:**
```bash
pip install replicate pydub anthropic loguru
export REPLICATE_API_TOKEN=your_token
export ANTHROPIC_API_KEY=your_key
```

2. **Estructura de archivos:**
- Copiar todos los m√≥dulos Python del c√≥digo proporcionado
- Crear config/medical_prompts.json
- Crear tests/fixtures/sample_audios/

3. **Pipeline b√°sico:**
```python
from src.transcription.thomasmol_client import thomasmol_client
from src.transcription.speaker_assigner import speaker_assigner
from src.quality.confidence_checker import confidence_checker

# Transcribir
result = thomasmol_client.transcribe("audio.mp3")

# Asignar speakers
segments = speaker_assigner.assign_speakers(
    result['transcription']['segments'],
    result['metadata']['num_speakers_detected']
)

# Validar
quality = confidence_checker.check(result['transcription'])
```

4. **Testing:**
```bash
python tests/create_test_audio.py
python tests/test_full_pipeline.py
```

### M√©tricas de √âxito

- ‚úÖ Confianza promedio > 90%
- ‚úÖ Velocidad < 2 segundos por audio de 20s
- ‚úÖ Diarizaci√≥n correcta en >80% de casos
- ‚úÖ SOAP generado en <5 segundos

---

**FIN DE DOCUMENTACI√ìN**